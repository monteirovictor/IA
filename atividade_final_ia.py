# -*- coding: utf-8 -*-
"""Final_IA_(rev2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sp7dD9ZHr6TUo6ViZil33Vdlz93sqiA7

#1 - Introdução ao problema

A **disponibilidade da água** é de suma importância para a **saúde pública**, seja para beber, para uso doméstico, para a produção de alimentos ou para fins recreativos. Melhorando o abastecimento de água, o saneamento básico e a **gestão dos recursos hídricos** podem impulsionar o crescimento econômico dos países e acelerar processos de **redução de pobreza**.

Mediante aos problemas elencados anteriormente, foi utilizado um conjunto de dados, chamado “water_potabilty”, de domínio público, para aplicar técnicas de aprendizado de máquina (ML) com o intuito de distinguir a qualidade da água em potável e não potável, de forma a demonstrar possível utilização de técnicas de ML na resolução de problema socioeconômicos.

---

# 2 - Conjunto de dados e suas caracteristicas

O Dataset “water_potability.csv”, contém as métricas de qualidade da água para 3276 corpos d'água diferentes.
"""

from google.colab import drive
drive.mount('/content/drive')

#Atividade 2 -> Rafael Faturini e Victor Monteiro

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

#importação de Dados
df= pd.read_csv("/content/drive/MyDrive/python/water_potability.csv")

print(df.info(verbose=True))

df[1:10]

# Informações estatísticas básicas do dataframe (media, desvio padrão, maximo, minimo)
df.describe( )

coluna1=df.iloc[:,0]
coluna2=df.iloc[:,1]
coluna3=df.iloc[:,2]
coluna4=df.iloc[:,3]
coluna5=df.iloc[:,4]
coluna6=df.iloc[:,5]
coluna7=df.iloc[:,6]
coluna8=df.iloc[:,7]
coluna9=df.iloc[:,8]

# Reduzimos os valores apenas de maneira ilustrativa para entender os dados faltantes
Acoluna = [coluna1,coluna2/10,coluna3/2000,coluna4,coluna5,coluna6/20,coluna7,coluna8,coluna9]

plt.boxplot(Acoluna)
plt.show()

# Fica evidente pela falta  dos Boxplots das colunas relativas ao ph (1), 
# Sulfate (5) e Trihalomethanes (8) que esses elementos possui dados faltantes

"""---

# 3 - Pré-Processamento

O pré-processamento é um conjunto de atividades que envolvem preparação, organização e estruturação dos dados. Trata-se de uma etapa fundamental que precede a realização de análises e predições. Durante a análise inicial, observamos a necessidade de utilizar métodos de refinamento da informação, como algoritmos de tratamento de valores faltantes em 3 propriedades (pH, sulfato e trihalometanos) e de remoção de outliers em todo o dataset, para viabilizar a treinamento correto dos métodos.

---

## 3.1 - Valores Faltantes
"""

#Missing Values

# -> Verificando a quantidade de dados nulos no dataframe
df.isna().sum()

# Commented out IPython magic to ensure Python compatibility.
# -> Mapa de Dados Faltantes


import missingno as msno
# %matplotlib inline
msno.matrix(df)

#inserindo valores por media
import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer

imp=SimpleImputer(missing_values=np.nan,strategy='mean')
df_221=pd.DataFrame(imp.fit_transform(df))
df_221.columns=df.columns
df_221.index=df.index
df_221.head()

msno.matrix(df_221)

"""## 3.2 - Remoção de Outliers"""

#Outliers

graphFirst=df_221['ph']
graphSecond=df_221['Sulfate']
graphThird=df_221['Trihalomethanes']
graph=[graphFirst,graphSecond,graphThird]

plt.boxplot(graph)
plt.xticks([1, 2, 3], ['ph', 'Sulfate', 'Trihalomethanes'])
plt.show()

# 1 - ph / 2 = sulfate / 3 - Trihalomethanes

#Técnica do Zscore para remoção de Outliers

Z = (df_221-df_221.mean())/df_221.std()
Z[20:25]

print('Numero de linhas antes da remoção de outliers = %d' % (Z.shape[0]))

Z2 = Z.loc[((Z > -3).sum(axis=1)==9) & ((Z <= 3).sum(axis=1)==9),:]
print('Numero de linhas após o tratamento = %d' % (Z2.shape[0]))

#Técnica Interquartílica para remoção de Outliers ->'ph'


#Tratamento dos Outliers para os valores de ph

#Calculando os Quartis
percentile25 = df_221['ph'].quantile(0.25)
percentile75 = df_221['ph'].quantile(0.75)

#Amplitude Interquartílica

iqr=percentile75-percentile25

#Limite superior e Limite inferior
upper_limit = percentile75 + 1.5 * iqr
lower_limit = percentile25 - 1.5 * iqr

#Buscando os Outliers
df_221[df_221['ph'] > upper_limit]
df_221[df_221['ph'] < lower_limit]

#aparando os dados ph

new_df = df_221[df_221['ph'] < upper_limit]
new_df.shape


new_df_cap = df_221.copy()
new_df_cap['ph'] = np.where(
    new_df_cap['ph'] > upper_limit,
    upper_limit,
    np.where(
        new_df_cap['ph'] < lower_limit,
        lower_limit,
        new_df_cap['ph']
    )
)

#Tratamento dos Outliers para os valores de Sulfate

#Calculando os Quartis
percentiles25 = df_221['Sulfate'].quantile(0.25)
percentiles75 = df_221['Sulfate'].quantile(0.75)

#Amplitude Interquartílica

iqrs=percentiles75-percentiles25

#Limite superior e Limite inferior
upper_limits = percentiles75 + 1.5 * iqrs
lower_limits = percentiles25 - 1.5 * iqrs

#Buscando os Outliers
df_221[df_221['Sulfate'] > upper_limits]
df_221[df_221['Sulfate'] < lower_limits]

#aparando os dados Sulfate

new_dfs = df_221[df_221['Sulfate'] < upper_limits]
new_dfs.shape


new_df_caps = df_221.copy()
new_df_caps['Sulfate'] = np.where(
    new_df_caps['Sulfate'] > upper_limits,
    upper_limits,
    np.where(
        new_df_caps['Sulfate'] < lower_limits,
        lower_limits,
        new_df_caps['Sulfate']
    )
)

#Tratamento dos Outliers para os valores de Trihalomethanes

#Calculando os Quartis
percentilet25 = df_221['Trihalomethanes'].quantile(0.25)
percentilet75 = df_221['Trihalomethanes'].quantile(0.75)

#Amplitude Interquartílica

iqrt=percentilet75-percentilet25

#Limite superior e Limite inferior
upper_limitt = percentilet75 + 1.5 * iqrt
lower_limitt = percentilet25 - 1.5 * iqrt

#Buscando os Outliers
df_221[df_221['Trihalomethanes'] > upper_limitt]
df_221[df_221['Trihalomethanes'] < lower_limitt]

#aparando os dados Trihalomethanes

new_dft = df_221[df_221['Trihalomethanes'] < upper_limitt]
new_dft.shape


new_df_capt = df_221.copy()
new_df_capt['Trihalomethanes'] = np.where(
    new_df_capt['Trihalomethanes'] > upper_limitt,
    upper_limitt,
    np.where(
        new_df_capt['Trihalomethanes'] < lower_limitt,
        lower_limitt,
        new_df_capt['Trihalomethanes']
    )
)

pOutliers=new_df_cap['ph']
sOutliers=new_df_caps['Sulfate']
tOutliers=new_df_capt['Trihalomethanes']
outliers_tratados=[pOutliers,sOutliers,tOutliers]
plt.boxplot(outliers_tratados)
plt.xticks([1, 2, 3], ['ph', 'Sulfate', 'Trihalomethanes'])
plt.show()

#Montagem de um novo dataframe, com o base no tratamento dos Outliers


Hardness=df_221['Hardness']	
Solids=df_221['Solids']	
Chloramines=df_221['Chloramines']
Conductivity=df_221['Conductivity']
Organic_carbon=df_221['Organic_carbon']	
Turbidity=df_221['Turbidity']	
Potability=df_221['Potability']
pOutliers=new_df_cap['ph']
sOutliers=new_df_caps['Sulfate']
tOutliers=new_df_capt['Trihalomethanes']


dataframe_outliers = pd.DataFrame(list(zip(pOutliers,Hardness,Solids,Chloramines,
sOutliers,Conductivity,Organic_carbon,tOutliers,Turbidity,Potability)),
columns=['ph','Hardness','Solids','Chloramines','Sulfate','Conductivity',
         'Organic_carbon','Trihalomethanes','Turbidity','Potability'])

#dataframe final, com os tratamentos
dataframe_outliers

#Exibição do resultado final, após o tratamento dos outliers
msno.matrix(dataframe_outliers)

#Separação das features e labels
X_elementos_agua = dataframe_outliers.iloc[:,0:9].values
y_elementos_agua = dataframe_outliers.iloc[:,9].values

"""---

# 3 - Random Forest

A primeira técnica de aprendizagem de máquina utilizada para obter a porcentagem de potabilidade da água foi o algoritmo Random Forest (Floresta aleatória), cujo seu processo de funcionamento dar-se por montar mini árvores de decisão. A sua utilização é grande valia, pois é capaz de compreender dados desconhecidos reduzindo overfiting, diferente de uma árvore com grande profundidade que tende a responder muito bem a dados conhecidos. O funcionamento deste classificador segue as etapas descritas abaixo:
1.	Seleção aleatória de algumas features.
2.	Seleção da feature mais adequada para a posição de nó raiz.
3.	Geração dos nós filhos.
4.	Repete os passos acima até que se atinja a quantidade de árvores desejada.
"""

# Divisão do conjunto de dados 
from sklearn import metrics
from sklearn.metrics import plot_confusion_matrix
from sklearn.ensemble import RandomForestClassifier

X_train, X_test, y_train, y_test = train_test_split(X_elementos_agua, y_elementos_agua,test_size=0.3,train_size=0.6,random_state=0)

# numero de arvores igual a 150
rf150 = RandomForestClassifier(n_estimators=150,random_state=0).fit(X_train, y_train)
print("acurácia para n_estimators= 150: ", rf150.score(X_test, y_test))

y_pred = rf150.predict(X_test)
print("classificação da melhor acurácia: \n",metrics.classification_report(y_test,y_pred))
plot_confusion_matrix(rf150, X_test, y_test, values_format = 'd',cmap=plt.cm.Blues)

"""---

# 4 - Rede Neural

A segunda técnica utilizada foi a implementação de Rede Neural Artificial que se baseia em um modelo matemático inspirado na estrutura neural de organismos inteligentes e que adquirem conhecimento através da experiência. As etapas básicas são:



*   Sinais são apresentados à entrada.
*   Cada sinal é multiplicado por um número, ou peso, que indica a sua influência na saída da unidade.
* É feita a soma ponderada dos sinais que produz um nível de atividade.
* Se este nível de atividade exceder um certo limite (threshold) a unidade produz uma determinada resposta de saída.
* A propriedade mais importante das redes neurais é a habilidade de aprender em seu ambiente e com isso melhorar seu desempenho, por um processo iterativo de ajustes aplicado a seus pesos, o treinamento.
"""

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report

X_train, X_test, y_train, y_test = train_test_split(X_elementos_agua, y_elementos_agua,test_size=0.3,train_size=0.6,random_state=0)
rede_neural_credit = MLPClassifier(max_iter=1500, tol=0.0000100,
                                   solver = 'adam', activation = 'relu',
                                   hidden_layer_sizes = (5,5))
rede_neural_credit.fit(X_train, y_train)

previsoes = rede_neural_credit.predict(X_test)
previsoes;
y_test;
accuracy_score(y_test, previsoes)

print("classificação da melhor acurácia: \n",metrics.classification_report(y_test,previsoes))
plot_confusion_matrix(rede_neural_credit, X_test, y_test, values_format = 'd',cmap=plt.cm.Blues)

"""---

# 5 - Conclusão

A modelagem e a previsão da qualidade da água são muito importantes para a proteção do meio ambiente e o desenvolvimento da sociedade. A construção de um modelo usando algoritmos avançados de inteligência artificial pode ser essencial para melhorar a eficiência e diminuir os custos desse processo no futuro, ajudando principalmente regiões em países economicamente vulneráveis. 

Nesta metodologia, dois diferentes tipos de algoritmo de inteligência artificial, rede neural MLP e Random Forest, foram usados para classificar a qualidade da água. Os modelos propostos foram avaliados segundo a sua acurácia na identificação dos dados de teste. O método que apresentou o melhor desempenho foi o Random Forest, sendo melhor que a segunda alternativa, com base nos valores obtidos.
"""

x = np.arange(3) 
y1 = [67, 64, 261] 
y2 = [61,33, 359] 
width = 0.2
plt.bar(x-0.2, y1, width, color='DarkBlue') 
plt.bar(x, y2, width, color='lightBlue') 

plt.xticks(x, ['Acurácia', 'Falsos positivos', 'Falsos Negativos']) 
plt.xlabel("Medidas") 
plt.ylabel("Valores") 
plt.legend(["Random Forest", "Rede Neural"]) 
plt.show()

"""As limitações deste estudo incluem seu conjunto de dados limitado, o desconhecimento da forma de medição dos dados e, consequentemente, a não aplicação de etapas aprofundadas de tratamento dos dados. Acreditamos que com mais informação disponível, os algoritmos devem apresentar uma melhora na previsão. Estudos futuros que apliquem formas alternativas de inteligência artificial, como outros modelos de redes neurais, e incorporem novas features de entrada podem chegar a melhores resultados."""