# -*- coding: utf-8 -*-
"""ai_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19iQCK5c8REIbd6vx2XW-FW8JBeg5ty99

# Atividade 1 - Pré-Processamento
"""

from google.colab import drive
drive.mount('/content/drive')

#Atividade 2 -> Rafael Faturini e Victor Monteiro

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
#importação de Dados
df= pd.read_csv("/content/drive/MyDrive/python/water_potability.csv")

print(df.info(verbose=True))

df[1:10]

# Informações estatísticas básicas do dataframe (media, desvio padrão, maximo, minimo)
df.describe( )

coluna1=df.iloc[:,0]
coluna2=df.iloc[:,1]
coluna3=df.iloc[:,2]
coluna4=df.iloc[:,3]
coluna5=df.iloc[:,4]
coluna6=df.iloc[:,5]
coluna7=df.iloc[:,6]
coluna8=df.iloc[:,7]
coluna9=df.iloc[:,8]

# reduzimos os valores apenas de maneira ilustrativa para entender os dados faltantes
Acoluna = [coluna1,coluna2/10,coluna3/2000,coluna4,coluna5,coluna6/20,coluna7,coluna8,coluna9]

plt.boxplot(Acoluna)
plt.show()

# Fica evidente pela falta  dos Boxplots das colunas relativas ao ph (1), 
# Sulfate (5) e Trihalomethanes (8) que esses elementos possui dados faltantes

#Missing Values

# -> Verificando a quantidade de dados nulos no dataframe
df.isna().sum()

# Commented out IPython magic to ensure Python compatibility.
# -> Mapa de Dados Faltantes


import missingno as msno
# %matplotlib inline
msno.matrix(df)

#inserindo valores por media
import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer

imp=SimpleImputer(missing_values=np.nan,strategy='mean')
df_221=pd.DataFrame(imp.fit_transform(df))
df_221.columns=df.columns
df_221.index=df.index
df_221.head()

msno.matrix(df_221)

#Outliers

graphFirst=df_221['ph']
graphSecond=df_221['Sulfate']
graphThird=df_221['Trihalomethanes']
graph=[graphFirst,graphSecond,graphThird]

plt.boxplot(graph)
plt.show()

#Técnica do Zscore para remoção de Outliers
Z = (df_221-df_221.mean())/df_221.std()
Z[20:25]

print('Numero de linhas antes da remoção de outliers = %d' % (Z.shape[0]))

Z2 = Z.loc[((Z > -3).sum(axis=1)==9) & ((Z <= 3).sum(axis=1)==9),:]
print('Numero de linhas após o tratamento = %d' % (Z2.shape[0]))

#Técnica Interquartílica para remoção de Outliers ->'ph'


#Tratamento dos Outliers para os valores de ph

#Calculando os Quartis
percentile25 = df_221['ph'].quantile(0.25)
percentile75 = df_221['ph'].quantile(0.75)

#Amplitude Interquartílica

iqr=percentile75-percentile25

#Limite superior e Limite inferior
upper_limit = percentile75 + 1.5 * iqr
lower_limit = percentile25 - 1.5 * iqr

#Buscando os Outliers
df_221[df_221['ph'] > upper_limit]
df_221[df_221['ph'] < lower_limit]

#aparando os dados ph

new_df = df_221[df_221['ph'] < upper_limit]
new_df.shape


new_df_cap = df_221.copy()
new_df_cap['ph'] = np.where(
    new_df_cap['ph'] > upper_limit,
    upper_limit,
    np.where(
        new_df_cap['ph'] < lower_limit,
        lower_limit,
        new_df_cap['ph']
    )
)

#Tratamento dos Outliers para os valores de Sulfate

#Calculando os Quartis
percentiles25 = df_221['Sulfate'].quantile(0.25)
percentiles75 = df_221['Sulfate'].quantile(0.75)

#Amplitude Interquartílica

iqrs=percentiles75-percentiles25

#Limite superior e Limite inferior
upper_limits = percentiles75 + 1.5 * iqrs
lower_limits = percentiles25 - 1.5 * iqrs

#Buscando os Outliers
df_221[df_221['Sulfate'] > upper_limits]
df_221[df_221['Sulfate'] < lower_limits]

#aparando os dados Sulfate

new_dfs = df_221[df_221['Sulfate'] < upper_limits]
new_dfs.shape


new_df_caps = df_221.copy()
new_df_caps['Sulfate'] = np.where(
    new_df_caps['Sulfate'] > upper_limits,
    upper_limits,
    np.where(
        new_df_caps['Sulfate'] < lower_limits,
        lower_limits,
        new_df_caps['Sulfate']
    )
)

#Tratamento dos Outliers para os valores de Trihalomethanes

#Calculando os Quartis
percentilet25 = df_221['Trihalomethanes'].quantile(0.25)
percentilet75 = df_221['Trihalomethanes'].quantile(0.75)

#Amplitude Interquartílica

iqrt=percentilet75-percentilet25

#Limite superior e Limite inferior
upper_limitt = percentilet75 + 1.5 * iqrt
lower_limitt = percentilet25 - 1.5 * iqrt

#Buscando os Outliers
df_221[df_221['Trihalomethanes'] > upper_limitt]
df_221[df_221['Trihalomethanes'] < lower_limitt]

#aparando os dados Trihalomethanes

new_dft = df_221[df_221['Trihalomethanes'] < upper_limitt]
new_dft.shape


new_df_capt = df_221.copy()
new_df_capt['Trihalomethanes'] = np.where(
    new_df_capt['Trihalomethanes'] > upper_limitt,
    upper_limitt,
    np.where(
        new_df_capt['Trihalomethanes'] < lower_limitt,
        lower_limitt,
        new_df_capt['Trihalomethanes']
    )
)

pOutliers=new_df_cap['ph']
sOutliers=new_df_caps['Sulfate']
tOutliers=new_df_capt['Trihalomethanes']
outliers_tratados=[pOutliers,sOutliers,tOutliers]
plt.boxplot(outliers_tratados)
plt.xticks([1, 2, 3], ['ph', 'Sulfate', 'Trihalomethanes'])
plt.show()

#Montagem de um novo dataframe, com o base no tratamento dos Outliers


Hardness=df_221['Hardness']	
Solids=df_221['Solids']	
Chloramines=df_221['Chloramines']
Conductivity=df_221['Conductivity']
Organic_carbon=df_221['Organic_carbon']	
Turbidity=df_221['Turbidity']	
Potability=df_221['Potability']
pOutliers=new_df_cap['ph']
sOutliers=new_df_caps['Sulfate']
tOutliers=new_df_capt['Trihalomethanes']


dataframe_outliers = pd.DataFrame(list(zip(pOutliers,Hardness,Solids,Chloramines,
sOutliers,Conductivity,Organic_carbon,tOutliers,Turbidity,Potability)),
columns=['ph','Hardness','Solids','Chloramines','Sulfate','Conductivity',
         'Organic_carbon','Trihalomethanes','Turbidity','Potability'])

#dataframe final, com os tratamentos
dataframe_outliers

#Exibição do resultado final, após o tratamento dos outliers
msno.matrix(dataframe_outliers)

#Amostragem 

Amostra = df_221.sample(frac=0.01, random_state=1)
Amostra

# Amostra Sistemática


# Selecionado um registro aleatório entre os valores de 0 a 10:
semente = np.random.choice(10, 1)

# Gerando um array que inicia em 0 e termina em 100 com um intervalo de 7:
indices = np.arange(0,20,semente)

amostra2 = df_221.loc[indices,:]
amostra2

"""#Atividade 2

# Tarefa 1 - Classificação Naive Bayes
"""

#Dataframe para aplicação do método

df_naivebayes=dataframe_outliers
df_naivebayes

#parametros previsores

X_elementos_agua = df_naivebayes.iloc[:,0:9].values
X_elementos_agua

#classe (Não potável e Potável)

y_elementos_agua=df_naivebayes.iloc[:,9].values
y_elementos_agua

"""# A) Teste/Treino Modelo

## Naive Bayes - Utilizando teste(1/3)/treino(2/3)
"""

# teste (1/3)/treino(2/3)
from sklearn.model_selection import train_test_split
# Divisão do conjunto de dados 
X_train, X_test, y_train, y_test = train_test_split(X_elementos_agua, y_elementos_agua,test_size=0.3,train_size=0.6,random_state=0)

#verificar dimensões dos subconjuntos
X_train.shape, X_test.shape, y_train.shape, y_test.shape

from sklearn.naive_bayes import GaussianNB

#treinamento do algoritmo

naive_qualidade_agua=GaussianNB()

#criação da Tabela de probabilidade
naive_qualidade_agua.fit(X_train, y_train)

y_pred = naive_qualidade_agua.predict(X_test)

#registro por classe 
naive_qualidade_agua.class_count_

#Probabilidade da qualidade de água
probabilidade_qualidade_agua=naive_qualidade_agua.class_prior_

print(f'A probabilidade de água não potável é:{probabilidade_qualidade_agua[0]*100:,.2f}%')

print(f'A probabilidade de água potável é:{probabilidade_qualidade_agua[1]*100:,.2f}%')

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
from sklearn.metrics import plot_confusion_matrix

#Predict the response for test dataset
y_pred = naive_qualidade_agua.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print(metrics.classification_report(y_test,y_pred))

plot_confusion_matrix(naive_qualidade_agua, X_test, y_test,values_format='d')

#Curva ROC  
metrics.plot_roc_curve(naive_qualidade_agua, X_test, y_test)

"""## Naive Bayes - Utilizando teste (1/4)/treino(3/4)"""

# teste (1/4)/treino(3/4)
from sklearn.model_selection import train_test_split
# Divisão do conjunto de dados 
X_train, X_test, y_train, y_test = train_test_split(X_elementos_agua, y_elementos_agua,test_size=0.25,train_size=0.75,random_state=0)

#verificar dimensões dos subconjuntos
X_train.shape, X_test.shape, y_train.shape, y_test.shape

#treinamento do algoritmo

naive_qualidade_agua2=GaussianNB()

#criação da Tabela de probabilidade
naive_qualidade_agua2.fit(X_train, y_train)

y_pred = naive_qualidade_agua2.predict(X_test)

#registro por classe 
naive_qualidade_agua2.class_count_

#Probabilidade da qualidade de água
probabilidade_qualidade_agua2=naive_qualidade_agua2.class_prior_

print(f'A probabilidade de água não potável é:{probabilidade_qualidade_agua2[0]*100:,.2f}%')

print(f'A probabilidade de água potável é:{probabilidade_qualidade_agua2[1]*100:,.2f}%')

#Predict the response for test dataset
y_pred = naive_qualidade_agua2.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print(metrics.classification_report(y_test,y_pred))

plot_confusion_matrix(naive_qualidade_agua2, X_test, y_test,values_format='d')

#Curva ROC  
metrics.plot_roc_curve(naive_qualidade_agua2, X_test, y_test)



"""# B) Validação Cruzada"""

#Teste/treino

from sklearn.model_selection import train_test_split
# Divisão do conjunto de dados 
X_train, X_test, y_train, y_test = train_test_split(X_elementos_agua, y_elementos_agua,random_state=0)

#verificar dimensões dos subconjuntos
X_train.shape, X_test.shape, y_train.shape, y_test.shape

#treinamento do algoritmo

naive_qualidade_agua_validacao_cruzada=GaussianNB()

#criação da Tabela de probabilidade
naive_qualidade_agua_validacao_cruzada.fit(X_train, y_train)

y_pred = naive_qualidade_agua_validacao_cruzada.predict(X_test)

#registro por classe 
naive_qualidade_agua_validacao_cruzada.class_count_

#Probabilidade da qualidade de água
prob=naive_qualidade_agua_validacao_cruzada.class_prior_

print(f'A probabilidade de água não potável é:{prob[0]*100:,.2f}%')

print(f'A probabilidade de água potável é:{prob[1]*100:,.2f}%')

"""## Validação Cruzada -> K=5"""

#Importação das Bibliotecas 

from sklearn.model_selection import cross_val_score # Cross Validation Function.
from sklearn.model_selection import KFold # KFold Class.

kfold  = KFold(n_splits=5, shuffle=True) # shuffle=True, Shuffle (embaralhar) the data.
cv_scores = cross_val_score(naive_qualidade_agua_validacao_cruzada,X_test, y_test, cv=kfold)

print('Mean cross-validation score: {:.3f}'.format(np.mean(cv_scores)))

"""## Validação Cruzada -> K=10"""

kfold  = KFold(n_splits=10, shuffle=True) # shuffle=True, Shuffle (embaralhar) the data.
cv_scores = cross_val_score(naive_qualidade_agua_validacao_cruzada,X_test, y_test, cv=kfold)

print('Mean cross-validation score: {:.3f}'.format(np.mean(cv_scores)))

"""# C) Repetição - Experimento A

## Naive Bayes - Teste(1/3)/Treino(2/3)
"""

X_train, X_test, y_train, y_test = train_test_split(X_elementos_agua, y_elementos_agua,test_size=0.33,train_size=0.66,random_state=0 , stratify = y_elementos_agua)

#treinamento do algoritmo

naive_qualidade_agua=GaussianNB()

#criação da Tabela de probabilidade
naive_qualidade_agua.fit(X_train, y_train)

y_pred = naive_qualidade_agua.predict(X_test)

#registro por classe 
naive_qualidade_agua.class_count_

#Probabilidade da qualidade de água
probabilidade_qualidade_agua=naive_qualidade_agua.class_prior_

print(f'A probabilidade de água não potável é:{probabilidade_qualidade_agua[0]*100:,.2f}%')

print(f'A probabilidade de água potável é:{probabilidade_qualidade_agua[1]*100:,.2f}%')

#Predict the response for test dataset
y_pred = naive_qualidade_agua.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print(metrics.classification_report(y_test,y_pred))

"""## Naive Bayes - Teste(1/4)/Treino(3/4)"""

X_train, X_test, y_train, y_test = train_test_split(X_elementos_agua, y_elementos_agua,test_size=0.25,train_size=0.75,random_state=0 , stratify = y_elementos_agua)

#treinamento do algoritmo

naive_qualidade_agua2=GaussianNB()

#criação da Tabela de probabilidade
naive_qualidade_agua2.fit(X_train, y_train)

y_pred = naive_qualidade_agua2.predict(X_test)

#registro por classe 
naive_qualidade_agua2.class_count_

#Probabilidade da qualidade de água
probabilidade_qualidade_agua2=naive_qualidade_agua2.class_prior_

print(f'A probabilidade de água não potável é:{probabilidade_qualidade_agua2[0]*100:,.2f}%')

print(f'A probabilidade de água potável é:{probabilidade_qualidade_agua2[1]*100:,.2f}%')

#Predict the response for test dataset
y_pred = naive_qualidade_agua2.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print(metrics.classification_report(y_test,y_pred))

"""# C) Repetição - Experimento B

## Validação Cruzada -> K=5
"""

from sklearn.model_selection import StratifiedKFold

SKFold1  = StratifiedKFold(n_splits=5, shuffle=True) # shuffle=True, Shuffle (embaralhar) the data.
cv_scores = cross_val_score(naive_qualidade_agua_validacao_cruzada,X_test, y_test, cv=SKFold1)

print('Mean cross-validation score: {:.3f}'.format(np.mean(cv_scores)))

"""
##Validação Cruzada -> K=10"""

SKFold2 = StratifiedKFold(n_splits=5, shuffle=True) # shuffle=True, Shuffle (embaralhar) the data.
cv_scores = cross_val_score(naive_qualidade_agua_validacao_cruzada,X_test, y_test, cv=SKFold2)

print('Mean cross-validation score: {:.3f}'.format(np.mean(cv_scores)))

"""# Tarefa 2 - Árvore de Decisão

#  Utilizando teste(1/3) e treino (2/3)
"""

# teste (1/3)/treino(2/3)
from sklearn.model_selection import train_test_split
# Divisão do conjunto de dados 
X_train, X_test, y_train, y_test = train_test_split(X_elementos_agua, y_elementos_agua,test_size=0.3,train_size=0.6,random_state=0)

#verificar dimensões dos subconjuntos
X_train.shape, X_test.shape, y_train.shape, y_test.shape

from sklearn import tree

#modelDT = tree.DecisionTreeClassifier() #critérios default
modelDT = tree.DecisionTreeClassifier(criterion="entropy", min_samples_split=35,max_depth=4)
modelDT = modelDT.fit(X_train, y_train)

#Predict the response for test dataset
y_pred = modelDT.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print(metrics.classification_report(y_test,y_pred))

plot_confusion_matrix(modelDT, X_test, y_test,values_format='d')

#Curva ROC  
metrics.plot_roc_curve(modelDT, X_test, y_test)

"""# Tuning de parâmetros com Grid Search


"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

parametros = {'criterion':['gini','entropy'],'splitter':['best','random'],
'min_samples_split':[2,5,10],'min_samples_leaf':[1,5,10]}

grid = GridSearchCV(DecisionTreeClassifier(), param_grid=parametros, cv=5)
grid.fit(X_train, y_train)

melhores_parametros=grid.best_params_
melhor_resultado=grid.best_score_
print(melhores_parametros)
print(melhor_resultado)